{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1b263b-3616-45d4-a82c-f003ea37413c",
   "metadata": {},
   "source": [
    "# üé¨ TMDb Data Extraction ‚Äì Financial & Certification Enrichment  \n",
    "**Author:** Joseph Tulani Aytch  \n",
    "**Last Updated:** Aug‚ÄØ2025  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Overview\n",
    "In **Part‚ÄØ1**, we saw that the IMDb dataset lacked financial metrics like budget and revenue ‚Äî critical for analyzing movie performance.  \n",
    "Here, we supplement the dataset with **The Movie Database (TMDb)** API to add:\n",
    "\n",
    "- **Budget** üí∞  \n",
    "- **Revenue** üìà  \n",
    "- **MPAA Certification** üéü (G, PG, PG‚Äë13, R)\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Stakeholder Request\n",
    "- Enrich the filtered IMDb dataset from Part‚ÄØ1 with budget, revenue, and US certification.\n",
    "- Proof‚Äëof‚Äëconcept: process movies from **2000** and **2001**.\n",
    "- Save one compressed CSV file per year.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ† Approach\n",
    "1. **Setup**: Import libraries, configure folders, load API key from a local JSON secret file.\n",
    "2. **Helper Functions**:\n",
    "   - `write_json()` ‚Üí append API results to JSON storage.\n",
    "   - `get_movie_with_rating()` ‚Üí retrieve details + certification.\n",
    "3. **Validation**: Test API calls with known titles.\n",
    "4. **Data Extraction**:\n",
    "   - Outer loop: iterate over years in scope.\n",
    "   - Inner loop: call TMDb API for each movie and append to JSON.\n",
    "5. **Output**:\n",
    "   - `final_tmdb_data_YYYY.csv.gz` ‚Üí per‚Äëyear results.\n",
    "   - `tmdb_results_combined.csv.gz` ‚Üí merged for downstream EDA.\n",
    "\n",
    "---\n",
    "\n",
    "## üìÇ Deliverables\n",
    "- `final_tmdb_data_2000.csv.gz`\n",
    "- `final_tmdb_data_2001.csv.gz`\n",
    "- `tmdb_results_combined.csv.gz`\n",
    "- Well‚Äëcommented API extraction and enrichment code.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö† Notes\n",
    "- TMDb API is rate‚Äëlimited ‚Äî large runs may take significant time.\n",
    "- API key is loaded locally, never committed to the repo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e786e89-2dfa-4801-a88a-5e174e84921a",
   "metadata": {},
   "source": [
    "> **üîë API Key Required**  \n",
    "> This notebook requires a valid **TMDb API key** to run.  \n",
    "> - You can request a free key at [https://developer.themoviedb.org/docs](https://developer.themoviedb.org/docs).  \n",
    "> - Store your key **securely** in a local file or environment variable ‚Äî never commit it to GitHub.  \n",
    "> - In this project, the key is read from a local JSON file at `~/.secret/TMDB_api.json`, which is excluded via `.gitignore`.  \n",
    "> - If the key is missing, API requests will fail. The notebook will still render static outputs for portfolio viewing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15e16f9-99af-4dc9-a97b-71f20bbfcea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tmdbsimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc141df8-dd80-4751-8ab8-d6258154aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Data directory ready: Data\n",
      "üìÑ Current files in Data/: ['final_akas.csv.gz', 'final_basics.csv.gz', 'final_ratings.csv.gz', 'final_tmdb_data_2000.csv.gz', 'final_tmdb_data_2001.csv.gz', 'title_basics.csv.gz', 'tmdb_api_results_2000.json', 'tmdb_api_results_2001.json', 'tmdb_results_combined.csv.gz']\n"
     ]
    }
   ],
   "source": [
    "import os, time, json\n",
    "import pandas as pd\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "# === 1. Setup folders ===\n",
    "data_dir = os.path.join(\"Data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÇ Data directory ready: {data_dir}\")\n",
    "\n",
    "# List current data files\n",
    "print(\"üìÑ Current files in Data/:\", os.listdir(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "536fe102-ff33-4344-9224-ae0c0a7ef958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key registered with tmdbsimple\n"
     ]
    }
   ],
   "source": [
    "# === 2. Load API credentials ===\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tmdbsimple as tmdb\n",
    "\n",
    "secret_path = Path.home() / \".secret\" / \"TMDB_api.json\"\n",
    "api_key = None\n",
    "\n",
    "try:\n",
    "    with open(secret_path) as f:\n",
    "        creds = json.load(f)\n",
    "        api_key = creds.get(\"api_key\")\n",
    "    if not api_key:\n",
    "        raise KeyError(\"Missing 'api_key' field.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è No API key file found at: {secret_path}\")\n",
    "except (json.JSONDecodeError, KeyError) as e:\n",
    "    print(f\"‚ö†Ô∏è Error reading API key: {e}\")\n",
    "\n",
    "if api_key:\n",
    "    tmdb.API_KEY = api_key\n",
    "    print(\"‚úÖ API key registered with tmdbsimple\")\n",
    "else:\n",
    "    print(\"üîí API key not available. Skipping live API calls.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18d6bfdc-0a27-4ab2-b9da-d57999f312be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Helper functions (unchanged logic, but still relative paths where applicable) ===\n",
    "def write_json(new_data, filename):\n",
    "    with open(filename, 'r+') as file:\n",
    "        file_data = json.load(file)\n",
    "        if isinstance(new_data, list) and isinstance(file_data, list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "            file_data.append(new_data)\n",
    "        file.seek(0)\n",
    "        json.dump(file_data, file)\n",
    "\n",
    "def get_movie_with_rating(movie_id):\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1'] == 'US':\n",
    "            info['certification'] = c['certification']\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cfb65c6-f38e-43b6-8a63-01f12c5937e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult': False,\n",
       " 'backdrop_path': '/bWoa6FtpnD2qByTVTmL5pAZUAKv.jpg',\n",
       " 'belongs_to_collection': None,\n",
       " 'budget': 29000000,\n",
       " 'genres': [{'id': 10749, 'name': 'Romance'}, {'id': 18, 'name': 'Drama'}],\n",
       " 'homepage': 'http://www.newline.com/properties/notebookthe.html',\n",
       " 'id': 11036,\n",
       " 'imdb_id': 'tt0332280',\n",
       " 'origin_country': ['US'],\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'The Notebook',\n",
       " 'overview': \"An epic love story centered around an older man who reads aloud to a woman with Alzheimer's. From a faded notebook, the old man's words bring to life the story about a couple who is separated by World War II, and is then passionately reunited, seven years later, after they have taken different paths.\",\n",
       " 'popularity': 14.7851,\n",
       " 'poster_path': '/rNzQyW4f8B8cQeg7Dgj3n6eT5k9.jpg',\n",
       " 'production_companies': [{'id': 12,\n",
       "   'logo_path': '/x33I3vv8nx1O7rECNN7X5MsAFoN.png',\n",
       "   'name': 'New Line Cinema',\n",
       "   'origin_country': 'US'},\n",
       "  {'id': 1565, 'logo_path': None, 'name': 'Avery Pix', 'origin_country': 'US'},\n",
       "  {'id': 2605,\n",
       "   'logo_path': None,\n",
       "   'name': 'Gran Via Productions',\n",
       "   'origin_country': 'US'}],\n",
       " 'production_countries': [{'iso_3166_1': 'US',\n",
       "   'name': 'United States of America'}],\n",
       " 'release_date': '2004-05-25',\n",
       " 'revenue': 115600000,\n",
       " 'runtime': 123,\n",
       " 'spoken_languages': [{'english_name': 'English',\n",
       "   'iso_639_1': 'en',\n",
       "   'name': 'English'}],\n",
       " 'status': 'Released',\n",
       " 'tagline': 'Behind every great love is a great story.',\n",
       " 'title': 'The Notebook',\n",
       " 'video': False,\n",
       " 'vote_average': 7.892,\n",
       " 'vote_count': 12024,\n",
       " 'certification': 'PG-13'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with known movie IDs\n",
    "get_movie_with_rating(\"tt0848228\")  # The Avengers\n",
    "get_movie_with_rating(\"tt0332280\")  # The Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6ce46f2-526b-4237-92a4-304293e56248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded basics dataset: 84,200 rows\n"
     ]
    }
   ],
   "source": [
    "# === 4. Load IMDb basics from Part 0 ===\n",
    "basics_path = os.path.join(data_dir, \"final_basics.csv.gz\")\n",
    "if not os.path.exists(basics_path):\n",
    "    raise FileNotFoundError(f\"Missing {basics_path} ‚Äî run Part‚ÄØ0 first.\")\n",
    "\n",
    "basics = pd.read_csv(basics_path)\n",
    "print(f\"‚úÖ Loaded basics dataset: {len(basics):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e7ea48-7df0-4091-a5bf-c2b2cac7e735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4bef165c7e4fd6a40e2ab7396c7e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc67f1480fc14e778c4e611969c8949e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies 2000:   0%|          | 0/207 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved 2000 data: Data\\final_tmdb_data_2000.csv.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3ec8fea3ed49ec98dd370f57448336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies 2001:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved 2001 data: Data\\final_tmdb_data_2001.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# === 5. Extraction loop ===\n",
    "errors = []\n",
    "YEARS_TO_GET = [2000, 2001]\n",
    "\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    json_file = os.path.join(data_dir, f\"tmdb_api_results_{YEAR}.json\")\n",
    "    csv_file  = os.path.join(data_dir, f\"final_tmdb_data_{YEAR}.csv.gz\")\n",
    "\n",
    "    # Ensure JSON exists\n",
    "    if not os.path.isfile(json_file):\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump([{'imdb_id': 0}], f)\n",
    "\n",
    "    # Filter for current year\n",
    "    df_year = basics.loc[basics['startYear'] == YEAR].copy()\n",
    "    movie_ids = df_year['tconst']\n",
    "\n",
    "    # Skip already stored IDs\n",
    "    previous_df = pd.read_json(json_file)\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f\"Movies {YEAR}\",\n",
    "                                  position=1, leave=True):\n",
    "        try:\n",
    "            temp = get_movie_with_rating(movie_id)\n",
    "            write_json(temp, json_file)\n",
    "            time.sleep(0.02)\n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])\n",
    "\n",
    "    # Save yearly CSV\n",
    "    final_year_df = pd.read_json(json_file)\n",
    "    final_year_df.to_csv(csv_file, compression=\"gzip\", index=False)\n",
    "    print(f\"üíæ Saved {YEAR} data: {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5b8c3a5-9a5d-4036-8e06-417bf2186f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined 2 files ‚Üí 2,586 rows total\n",
      "üíæ Saved merged dataset to: Data\\tmdb_results_combined.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# === 6. Merge yearly files for downstream EDA ===\n",
    "import glob\n",
    "\n",
    "yearly_files = sorted(glob.glob(os.path.join(data_dir, \"final_tmdb_data_*.csv.gz\")))\n",
    "df_list = [pd.read_csv(f) for f in yearly_files]\n",
    "tmdb_results_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "combined_path = os.path.join(data_dir, \"tmdb_results_combined.csv.gz\")\n",
    "tmdb_results_combined.to_csv(combined_path, compression=\"gzip\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Combined {len(yearly_files)} files ‚Üí {len(tmdb_results_combined):,} rows total\")\n",
    "print(f\"üíæ Saved merged dataset to: {combined_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078cfa7-9c8c-49ad-9f03-fd16483b5db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
